{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown\n",
    "import time\n",
    "from typing import Union\n",
    "# import librosa \n",
    "from yt_dlp import YoutubeDL\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "# import pytube\n",
    "import re\n",
    "import whisper\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# video_has_transcript = \"https://www.youtube.com/watch?v=rQU75JsSSxw&ab_channel=ToxicDrunker\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# part I: get transcript "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_transcript(url: str=None, path: str=None, output_timestamp: bool=False) -> str:\n",
    "  \n",
    "  if url:\n",
    "    transcript = check_existing_transcript(url) \n",
    "    print(transcript)\n",
    "\n",
    "    if not transcript:\n",
    "      file = download_from_youtube(url)\n",
    "    else:\n",
    "      return transcript\n",
    "\n",
    "  elif path: \n",
    "    file = load_from_local_file(path)\n",
    "    \n",
    "  transcript = convert_speech_to_text(file)\n",
    "    \n",
    "  return transcript \n",
    "\n",
    "\n",
    "def get_video_id(url: str) -> str:\n",
    "    \"\"\"The `get_video_id` function is extracting the unique video ID from a YouTube \n",
    "    video URL. It uses a regular expression to search for the video ID pattern in \n",
    "    the URL and returns the extracted video ID as a string.\n",
    "\n",
    "    Args:\n",
    "        url (str): _description_\n",
    "\n",
    "    Returns:\n",
    "        str: _description_\n",
    "    \"\"\"\n",
    "    # [TODO]: try and raise error\n",
    "    return re.search(r\"(?:v=|\\/)([0-9A-Za-z_-]{11}).*\", url).group(1)\n",
    "\n",
    "\n",
    "def check_existing_transcript(url: str, language_code=\"en\", manual_only=True, output_timestamp=False) -> Union[str, bool]:\n",
    "  \"\"\"\n",
    "  `check_existing_transcript` is a function that checks if a transcript exists for \n",
    "  a given YouTube video URL. It first extracts the video ID from the URL and then \n",
    "  attempts to list the available transcripts for that video using the YouTubeTranscriptApi. \n",
    "  If the transcript is found and matches the specified language code and generation type \n",
    "  (manual or not), it retrieves the transcript text. The function also has the option to \n",
    "  output timestamps along with the transcript text. If any errors occur during the process, \n",
    "  it will return False.\n",
    "\n",
    "  Args:\n",
    "      url (str): the url of the YouTube video \n",
    "      language_code (str, optional): desired language code for the existing transcript. Defaults to \"en\".\n",
    "      manual_only (bool, optional): if only download manual transcript. Defaults to False.\n",
    "      output_timestamp (bool, optional): if output timestamp. Defaults to False.\n",
    "\n",
    "  Returns:\n",
    "      transcript: transcript in string format or False if the transcript does not exist\n",
    "  \"\"\"\n",
    "  # [TODO] use logging to capture errors\n",
    "  video_id = get_video_id(url)\n",
    "  try:\n",
    "    transcript_list = YouTubeTranscriptApi.list_transcripts(video_id)\n",
    "    transcript_list = {t.language_code: not t.is_generated for t in transcript_list}\n",
    "    print(transcript_list)\n",
    "  except Exception as e:\n",
    "    print(e)\n",
    "    return False\n",
    "  \n",
    "  if language_code in transcript_list and transcript_list[language_code] is manual_only:\n",
    "    transcription_ = YouTubeTranscriptApi.get_transcript(video_id, languages=[language_code])\n",
    "    if output_timestamp:\n",
    "      transcript = \"\"\n",
    "      for tr in transcription_:\n",
    "        start = time.strftime(\"%H:%M:%S\", time.gmtime(tr[\"start\"]))\n",
    "        end = time.strftime(\"%H:%M:%S\", time.gmtime(tr[\"start\"]))\n",
    "        transcript += f\"[{start}-{end}] {tr['text']}\" + \"\\n\"\n",
    "    else:\n",
    "      transcript = \"\"\n",
    "      for tr in transcription_:\n",
    "        transcript += tr[\"text\"]+\" \"\n",
    "  else:\n",
    "    print(f\"the specified language code {language_code} does not exist.\")\n",
    "    return False\n",
    "    \n",
    "  return transcript\n",
    "\n",
    "\n",
    "def download_from_youtube(url, output_path=\"\"):\n",
    "  \"\"\"_summary_\n",
    "\n",
    "  Args:\n",
    "      url (_type_): _description_\n",
    "      output_path (str, optional): _description_. Defaults to \"\".\n",
    "  \"\"\"\n",
    "  \n",
    "  youtube_dl_opts = {\n",
    "  \"outtmpl\": output_path+\"%(title)s.%(ext)s\",\n",
    "  \"format\": \"bestaudio/best\",\n",
    "  'postprocessors': [{\n",
    "    'key': 'FFmpegExtractAudio', \n",
    "    'preferredcodec': 'mp3', \n",
    "    'preferredquality': '192'\n",
    "  }]\n",
    "}\n",
    "\n",
    "  with YoutubeDL(youtube_dl_opts) as ydl:\n",
    "    info_dict = ydl.extract_info(url, download=True)\n",
    "\n",
    "  return ydl.prepare_filename(info_dict).replace(\"webm\", \"mp3\")\n",
    "\n",
    "\n",
    "def load_from_local_file(path: str) -> None:\n",
    "  \"\"\"_summary_\n",
    "\n",
    "  Args:\n",
    "      path (str): _description_\n",
    "\n",
    "  Returns:\n",
    "      _type_: _description_\n",
    "  \"\"\"\n",
    "  # audio_file, _ = librosa.load(path)\n",
    "  return path\n",
    "\n",
    "def convert_speech_to_text(file, model_size=\"tiny\", language=\"en\", fp16=False, verbose=False):\n",
    "  \"\"\"The `convert_speech_to_text` function is responsible for converting \n",
    "  speech audio data into text. It takes the audio file as input along with \n",
    "  optional parameters such as the model size, language, whether to use \n",
    "  fp16 precision, and a verbosity flag.\n",
    "\n",
    "  Args:\n",
    "      file (_type_): _description_\n",
    "      model_size (str, optional): _description_. Defaults to \"tiny\".\n",
    "      language (str, optional): _description_. Defaults to \"en\".\n",
    "      fp16 (bool, optional): _description_. Defaults to False.\n",
    "      verbose (bool, optional): _description_. Defaults to False.\n",
    "\n",
    "  Returns:\n",
    "      _type_: _description_\n",
    "  \"\"\"\n",
    "  model = whisper.load_model(model_size)\n",
    "  result = model.transcribe(file, language=language, fp16=fp16, verbose=verbose)\n",
    "  return result\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'en': False}\n",
      "the specified language code en does not exist.\n",
      "False\n",
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=rZvhFcA-n5c&ab_channel=SNARLED\n",
      "[youtube] rZvhFcA-n5c: Downloading webpage\n",
      "[youtube] rZvhFcA-n5c: Downloading ios player API JSON\n",
      "[youtube] rZvhFcA-n5c: Downloading android player API JSON\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] Skipping player responses from android clients (got player responses for video \"aQvGIIdgFDM\" instead of \"rZvhFcA-n5c\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] rZvhFcA-n5c: Downloading m3u8 information\n",
      "[info] rZvhFcA-n5c: Downloading 1 format(s): 251\n",
      "[download] Hamilton Musical Explained ⧸⧸ 3 Minutes Or Less ｜ Snarled.webm has already been downloaded\n",
      "[download] 100% of    2.73MiB\n",
      "[ExtractAudio] Destination: Hamilton Musical Explained ⧸⧸ 3 Minutes Or Less ｜ Snarled.mp3\n",
      "Deleting original file Hamilton Musical Explained ⧸⧸ 3 Minutes Or Less ｜ Snarled.webm (pass -k to keep)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16422/16422 [00:10<00:00, 1521.19frames/s]\n"
     ]
    }
   ],
   "source": [
    "# sanitary check \n",
    "\n",
    "# url = \"https://www.youtube.com/watch?v=B3szaVzQx0o&ab_channel=MarquesBrownlee\" # has manual transcript \n",
    "# url = \"https://www.youtube.com/watch?v=4COqwI5-YFA&ab_channel=TheStraitsTimes\" # singlish \n",
    "# url = \"https://www.youtube.com/watch?v=b5XgNrkccxc&ab_channel=JaredHenderson\"\n",
    "\n",
    "\n",
    "# url = \"https://www.youtube.com/watch?v=rZvhFcA-n5c&ab_channel=SNARLED\"` is a commented-out line of code. This means that it is not currently being executed as part of the program. It is likely being used as a reference or placeholder for a YouTube video URL that may be used in the future.\n",
    "url = \"https://www.youtube.com/watch?v=rZvhFcA-n5c&ab_channel=SNARLED\"\n",
    "\n",
    "tr = get_transcript(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Hi, I'm Sabrina and I love Hamilton and American musical, but it's three hours long so I'm gonna compress it into three minutes. Let's go. There's this bastard orphan son of a hornist Scott with a who lives a super depressing life, but he escapes poverty by educating himself and writing a letter in earning a scholarship to King's College. Fast forward to 1776, Hamilton graduates and is now stalking his idol Aaron Burr, who just tells him to shut up and smile, then John Lawrence, her Achilles Mulligan and the Marquis to left by Ed Walkin. In Hamilton is like, I have found my people. And they also are yelling about starting our evolution while Burr's in the corner judging them. But the Revolutionary War starts in general George Washington needs a right hand man. Burr walks in his like, mate, you should pick me and Washington's like, uh, I pick Hamilton. Then in 1780 when there's ball burrs, like, at least there's one thing Hamilton and I are both equal in picking up the ladies. You see those stylish sisters and Jelika, Eliza, and Peggy, well I could and then Angelica and Eliza fall in up with Hamilton. Eliza's helpless so Angelica left her half him even if it means she'll never be satisfied. And then back to the war, Washington appoints Charles Lee as general who proceeds to suck at his job and gets fired. Lee starts playing Washington and Hamilton is like, so much to shoot that guy. Lauren shoots that guy, but they win the war. And that's just a start. Hamilton becomes a lawyer for poses in uniform of government and starts defending a new US constitution by writing 51 essays. Everyone tells him, I'm glad you've done so much. You can come down. And Hamilton is just in the corner, writing more essays. And it's 1789. Thomas Jefferson is coming home from France to become the secretary of state for sort of business. Tell Hamilton to shut up about his new financial system. Now Hamilton is stressing because if he can convince Jefferson he loses his job. Eliza's like, take a break. And Hamilton's like, no, you take a break. So they do when Hamilton gets lonely and cheats on her and gets blackmailed. He goes on the day with Jefferson. They decide to put the capital in the South and exchange for a passing Hamilton's financial plan. All the wild birds just really salty about being left out. Soon enough Hamilton and Jefferson are back to finding when Washington agrees with Hamilton to not support the retrovolution. And now Jefferson and Burr are salty together because Washington just loves Hamilton. And then Washington steps down this president. Without his puppy in charge of salt swat water put the final nail in Hamilton's coffin, blackmail him for emphor abysdling money from the government. And Hamilton's like, no, I didn't do that. I'm just cheating on my wife. Stupid. Before the salt swat the blackmail in two, Hamilton decides to publish a news first and Eliza's just like, dude, and starts hitting fire and stuff. People rightfully start calling Hamilton his gild. But his son Philip is not having it. He challenges a guy to a duel in Hamilton's son. Don't shoot him. Shoot for the sky instead. And surprise surprise. Philip dies. Now Hamilton is family move up town in our really evil. But then 1800 rolls around Jefferson and Burr both running for the presidency. Hamilton is never going to miss a chance to miss with Burr. He privileged Jefferson and Jefferson wins and Burr passively challenges him to a duel. During the duel Hamilton, no learn the single thing from his dead son. Also shoots at the sky and surprise the prize. Hamilton dies. Also Eliza started an orphanage and I cried.\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Markdown(f[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # sanitary check \n",
    "\n",
    "# # url = \"https://www.youtube.com/watch?v=B3szaVzQx0o&ab_channel=MarquesBrownlee\" # has manual transcript \n",
    "# # url = \"https://www.youtube.com/watch?v=4COqwI5-YFA&ab_channel=TheStraitsTimes\" # singlish \n",
    "# path = \"Lawrence Wong sworn in as Singapore’s fourth Prime Minister.mp3\"\n",
    "\n",
    "# f = load_audio_file(path=path)\n",
    "# f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"transcript.txt\", \"w\") as file:\n",
    "  file.write(tr[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# part II: RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import openai\n",
    "\n",
    "_ = load_dotenv(find_dotenv())\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "# from llama_index.core import Document\n",
    "\n",
    "# load the document using `SimpleDirectoryReader`\n",
    "# which supports a range of document types based on \n",
    "# their extension\n",
    "document = SimpleDirectoryReader(\n",
    "  input_files=[\"transcript.txt\"]\n",
    ").load_data()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import SentenceWindowNodeParser\n",
    "\n",
    "node_parser = SentenceWindowNodeParser.from_defaults(\n",
    "  window_size=2,\n",
    "  window_metadata_key=\"window\",\n",
    "  original_text_metadata_key=\"original_text\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # another alternative is to build base nodes \n",
    "# # using `SentenceSplitter`\n",
    "\n",
    "# from llama_index.core.node_parser import SentenceSplitter\n",
    "\n",
    "# # base node parser is a sentence splitter\n",
    "# text_splitter = SentenceSplitter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/x3/z5c7sxc131d8t8hhqfw7x3780000gn/T/ipykernel_11803/2444352526.py:8: DeprecationWarning: Call to deprecated class method from_defaults. (ServiceContext is deprecated, please use `llama_index.settings.Settings` instead.) -- Deprecated since version 0.10.0.\n",
      "  sentence_context = ServiceContext.from_defaults(\n"
     ]
    }
   ],
   "source": [
    "# building the index\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core import ServiceContext\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo\", temperature=0.1)\n",
    "\n",
    "sentence_context = ServiceContext.from_defaults(\n",
    "  llm=llm,\n",
    "  embed_model=HuggingFaceEmbedding(\"BAAI/bge-small-en-v1.5\"),\n",
    "  node_parser=node_parser\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex\n",
    "\n",
    "sentence_index = VectorStoreIndex.from_documents(\n",
    "  [document],\n",
    "  service_context=sentence_context\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building the postprocessor:\n",
    "# use the `MetadataReplacementPostProcessor` to replace the sentence in each node \n",
    "# with its surrounding context\n",
    "\n",
    "from llama_index.core.postprocessor import MetadataReplacementPostProcessor\n",
    "\n",
    "query_engine = sentence_index.as_query_engine(\n",
    "  similarity_top_k=2,\n",
    "  node_postprocessors=[\n",
    "    MetadataReplacementPostProcessor(target_metadata_key=\"window\")\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The video provides a glimpse into the conflicts and challenges faced by various characters during a historical period, including duels, appointments, and betrayals, ultimately leading to victories despite the obstacles encountered.\n"
     ]
    }
   ],
   "source": [
    "query = \"summarize the video\"\n",
    "\n",
    "window_response = query_engine.query(\n",
    "  query\n",
    ")\n",
    "\n",
    "print(window_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The video provides a glimpse into the conflicts and challenges faced by various characters during a historical period, including duels, appointments, and betrayals, ultimately leading to victories despite the obstacles encountered."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(window_response.response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_sentence_window_rag(query: str, api_key: str, file_path: str) -> str:\n",
    "  \n",
    "  openai.api_key = api_key\n",
    "  \n",
    "  document = SimpleDirectoryReader(input_files=[file_path]).load_data()[0]\n",
    "  \n",
    "  node_parser = SentenceWindowNodeParser.from_defaults(\n",
    "    window_size=2,\n",
    "    window_metadata_key=\"window\",\n",
    "    original_text_metadata_key=\"original_text\"\n",
    "  )\n",
    "  \n",
    "  llm = OpenAI(model=\"gpt-3.5-turbo\", temperature=0.1)\n",
    "\n",
    "  sentence_context = ServiceContext.from_defaults(\n",
    "    llm=llm,\n",
    "    embed_model=HuggingFaceEmbedding(\"BAAI/bge-small-en-v1.5\"),\n",
    "    node_parser=node_parser\n",
    "  )\n",
    "  \n",
    "  sentence_index = VectorStoreIndex.from_documents(\n",
    "    [document],\n",
    "    service_context=sentence_context\n",
    "  )\n",
    "  \n",
    "  query_engine = sentence_index.as_query_engine(\n",
    "    similarity_top_k=2,\n",
    "    node_postprocessors=[\n",
    "      MetadataReplacementPostProcessor(target_metadata_key=\"window\")\n",
    "    ]\n",
    "  )\n",
    "  \n",
    "  window_response = query_engine.query(query)\n",
    "  \n",
    "  return window_response.response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# part III: putting it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'en': False}\n",
      "the specified language code en does not exist.\n",
      "False\n",
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=rZvhFcA-n5c&ab_channel=SNARLED\n",
      "[youtube] rZvhFcA-n5c: Downloading webpage\n",
      "[youtube] rZvhFcA-n5c: Downloading ios player API JSON\n",
      "[youtube] rZvhFcA-n5c: Downloading android player API JSON\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] Skipping player responses from android clients (got player responses for video \"aQvGIIdgFDM\" instead of \"rZvhFcA-n5c\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] rZvhFcA-n5c: Downloading m3u8 information\n",
      "[info] rZvhFcA-n5c: Downloading 1 format(s): 251\n",
      "[download] Destination: Hamilton Musical Explained ⧸⧸ 3 Minutes Or Less ｜ Snarled.webm\n",
      "[download] 100% of    2.73MiB in 00:00:01 at 2.09MiB/s   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ExtractAudio] Destination: Hamilton Musical Explained ⧸⧸ 3 Minutes Or Less ｜ Snarled.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting original file Hamilton Musical Explained ⧸⧸ 3 Minutes Or Less ｜ Snarled.webm (pass -k to keep)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "100%|██████████| 16422/16422 [00:14<00:00, 1165.41frames/s]\n"
     ]
    }
   ],
   "source": [
    "url = \"https://www.youtube.com/watch?v=rZvhFcA-n5c&ab_channel=SNARLED\"\n",
    "\n",
    "tr = get_transcript(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"transcript.txt\", \"w\") as file:\n",
    "  file.write(tr[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/x3/z5c7sxc131d8t8hhqfw7x3780000gn/T/ipykernel_11803/2639709756.py:15: DeprecationWarning: Call to deprecated class method from_defaults. (ServiceContext is deprecated, please use `llama_index.settings.Settings` instead.) -- Deprecated since version 0.10.0.\n",
      "  sentence_context = ServiceContext.from_defaults(\n"
     ]
    }
   ],
   "source": [
    "q = \"summarize the video\"\n",
    "_ = load_dotenv(find_dotenv())\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "path = \"transcript.txt\"\n",
    "\n",
    "answer = query_sentence_window_rag(query=q, api_key=api_key, file_path=path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The video discusses the challenges faced by Hamilton's son Philip, who engages in a duel to defend his father's honor. Additionally, it highlights the sacrifices made by Angelica for her sister Eliza, the struggles of General Charles Lee during the war, and the eventual victory achieved with the help of Hamilton and others."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
